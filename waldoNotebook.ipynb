{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c613cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Creating new Waldo samples...\n",
      "Converting numpy arrays into tensors...\n",
      "Waldo:NotWaldo Count :  7037 : 6940\n",
      "Dataset loaded\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "#  PREPROCESSING\n",
    "# ================\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as tf \n",
    "from torchvision import datasets\n",
    "#torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "def loadDirectory(filepath, isOrig):\n",
    "    # load directory\n",
    "    files = glob.glob(filepath)\n",
    "\n",
    "    arr = []\n",
    "    for fl in files:\n",
    "        img = cv2.imread(fl)\n",
    "\n",
    "        # resize image to 256x256\n",
    "        if(isOrig != True and img.shape[0] != 256): \n",
    "            img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        arr.append(img)\n",
    "\n",
    "    return arr\n",
    "\n",
    "def numpyToTensor(arr):\n",
    "    #convert to tensor\n",
    "    arr = np.array(arr)\n",
    "    arr = arr.transpose((0, 3, 1, 2))\n",
    "    tensorList = torch.FloatTensor(arr)\n",
    "\n",
    "    return tensorList\n",
    "\n",
    "def createNewWaldoSamples(notWaldos, overlay):\n",
    "    newWaldos = []\n",
    "    oRows, oCols, oChannels = overlay.shape\n",
    "    for img in notWaldos:\n",
    "        newImg = img\n",
    "        iRows, iCols, iChannels = newImg.shape\n",
    "        newImg = np.dstack([newImg, np.ones((iRows, iCols), dtype='uint8') * 255])\n",
    "\n",
    "        randX = random.randint(0, iRows-oRows)\n",
    "        randY = random.randint(0, iCols-oCols)\n",
    "\n",
    "        aOverlay = overlay[:, :, 3] / 255.0\n",
    "        aImg = 1.0 - aOverlay\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            newImg[randX:randX+oRows, randY:randY+oCols, c] = (aOverlay * overlay[:, :, c] + aImg * newImg[randX:randX+oRows, randY:randY+oCols, c])\n",
    "\n",
    "        newWaldos.append(newImg[:, :, :3])\n",
    "    \n",
    "    return newWaldos\n",
    "        \n",
    "# Loading images datasets\n",
    "print(\"Loading dataset...\")\n",
    "originalImg = loadDirectory(\"./original-images/*.jpg\", True)\n",
    "\n",
    "waldo64 = loadDirectory(\"./64/waldo/*.jpg\", False)\n",
    "notWaldo64 = loadDirectory(\"./64/notwaldo/*.jpg\", False)\n",
    "\n",
    "waldo128 = loadDirectory(\"./128/waldo/*.jpg\", False)\n",
    "notWaldo128 = loadDirectory(\"./128/notwaldo/*.jpg\", False)\n",
    "\n",
    "waldo256 = loadDirectory(\"./256/waldo/*.jpg\", False)\n",
    "notWaldo256 = loadDirectory(\"./256/notwaldo/*.jpg\", False)\n",
    "\n",
    "# Creating new Waldo samples by overlaying a Waldo png over a notWaldo sample\n",
    "print(\"Creating new Waldo samples...\")\n",
    "waldoOverlay64 = cv2.imread('./waldo64.png', cv2.IMREAD_UNCHANGED)\n",
    "waldoOverlay128 = cv2.imread('./waldo128.png', cv2.IMREAD_UNCHANGED)\n",
    "waldoOverlay256 = cv2.imread('./waldo256.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "moreWaldo64 = createNewWaldoSamples(notWaldo64, waldoOverlay64)\n",
    "moreWaldo128 = createNewWaldoSamples(notWaldo128, waldoOverlay128)\n",
    "moreWaldo256 = createNewWaldoSamples(notWaldo256, waldoOverlay256)\n",
    "\n",
    "# Converting numpy arrays into tensors (TODO: FINISH CONVERSION FUNCTION)\n",
    "print(\"Converting numpy arrays into tensors...\")\n",
    "waldo64Tensor = numpyToTensor(waldo64)\n",
    "waldo128Tensor = numpyToTensor(waldo128)\n",
    "waldo256Tensor = numpyToTensor(waldo256)\n",
    "\n",
    "moreWaldo64Tensor = numpyToTensor(moreWaldo64)\n",
    "moreWaldo128Tensor = numpyToTensor(moreWaldo128)\n",
    "moreWaldo256Tensor = numpyToTensor(moreWaldo256)\n",
    "\n",
    "notWaldo64Tensor = numpyToTensor(notWaldo64)\n",
    "notWaldo128Tensor = numpyToTensor(notWaldo128)\n",
    "notWaldo256Tensor = numpyToTensor(notWaldo256)\n",
    "\n",
    "# Combining into two lists: waldos and not waldos\n",
    "waldos = torch.cat((waldo64Tensor, waldo128Tensor, waldo256Tensor, moreWaldo64Tensor, moreWaldo128Tensor, moreWaldo256Tensor), 0)\n",
    "notWaldos = torch.cat((notWaldo64Tensor, notWaldo128Tensor, notWaldo256Tensor), 0)\n",
    "\n",
    "# All values inbetween 0 and 1\n",
    "waldos = waldos / 255.0\n",
    "notWaldos = notWaldos / 255.0\n",
    "\n",
    "print(\"Waldo:NotWaldo Count : \", waldos.size(dim=0), \":\", notWaldos.size(dim=0))\n",
    "\n",
    "# Create labels & combine\n",
    "waldoLabels = torch.cat((torch.ones(len(waldos)), torch.zeros(len(notWaldos))), 0)\n",
    "allWaldos = torch.cat((waldos, notWaldos), 0)\n",
    "\n",
    "waldoDataset = torch.utils.data.TensorDataset(allWaldos, waldoLabels)\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "958e5ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Initialized\n",
      "Dataset shuffled\n"
     ]
    }
   ],
   "source": [
    "# ============\n",
    "#   THE CNN\n",
    "# ============\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Network should output whether or not the input image has waldo in it\n",
    "class WaldoFinder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaldoFinder, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=256)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=128)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=32, stride=1, padding=0)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    #Forward function - convolvs down to 16x16 image and ultimately outputs 1 or 0\n",
    "    def forward(self, t):\n",
    "        t = self.conv1(t)\n",
    "        t = self.batchNorm1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout1(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = self.batchNorm2(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout2(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        t = self.conv3(t)\n",
    "        t = self.batchNorm3(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout3(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        t = self.conv4(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "waldoFinder = WaldoFinder()\n",
    "print(\"Network Initialized\")\n",
    "\n",
    "# Divide into training and test set\n",
    "tenPercent = int(len(waldoDataset) * 0.1)\n",
    "ninetyPercent = len(waldoDataset) - tenPercent\n",
    "trainSet, testSet = torch.utils.data.random_split(waldoDataset, [ninetyPercent, tenPercent])\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet, shuffle=True, batch_size=10)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, shuffle=True, batch_size=10)\n",
    "print(\"Dataset shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7951b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining training...\n",
      "Batch  0 :  0.6281522512435913\n",
      "Batch  1 :  183.32867431640625\n",
      "Batch  2 :  4.3555498123168945\n",
      "Batch  3 :  15.758875846862793\n",
      "Batch  4 :  58.70960235595703\n",
      "Batch  5 :  29.72129249572754\n",
      "Batch  6 :  0.0\n",
      "Batch  7 :  9.630595207214355\n",
      "Batch  8 :  3.8423163890838623\n",
      "Batch  9 :  0.31772178411483765\n",
      "Batch  10 :  2.6921546459198\n",
      "Batch  11 :  20.500654220581055\n",
      "Batch  12 :  36.20126724243164\n",
      "Batch  13 :  6.551748752593994\n",
      "Batch  14 :  29.972278594970703\n",
      "Batch  15 :  0.0\n",
      "Batch  16 :  0.0\n",
      "Batch  17 :  10.751923561096191\n",
      "Batch  18 :  0.007122138049453497\n",
      "Batch  19 :  31.92510986328125\n",
      "Batch  20 :  0.0\n",
      "Batch  21 :  0.0\n",
      "Batch  22 :  17.84917449951172\n",
      "Batch  23 :  0.0\n",
      "Batch  24 :  68.47174072265625\n",
      "Batch  25 :  8.520901679992676\n",
      "Batch  26 :  2.802706480026245\n",
      "Batch  27 :  0.0\n",
      "Batch  28 :  0.0\n",
      "Batch  29 :  1.2680915594100952\n",
      "Batch  30 :  8.655827522277832\n",
      "Batch  31 :  8.95247745513916\n",
      "Batch  32 :  0.0\n",
      "Batch  33 :  0.029461484402418137\n",
      "Batch  34 :  0.0002398830110905692\n",
      "Batch  35 :  28.28280258178711\n",
      "Batch  36 :  67.7721176147461\n",
      "Batch  37 :  0.0019618752412497997\n",
      "Batch  38 :  50.47372055053711\n",
      "Batch  39 :  10.022759437561035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/98/9by9b4t56nj5y36zn3zvh8_m0000gn/T/ipykernel_13484/2722136082.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Loop\n",
    "optimizer = optim.Adam(waldoFinder.parameters(), lr=.01)\n",
    "#lossFunc = nn.CrossEntropyLoss()\n",
    "lossFunc = nn.BCEWithLogitsLoss()\n",
    "\n",
    "i = 0\n",
    "print(\"Begining training...\")\n",
    "for items, labels in trainLoader:\n",
    "    optimizer.zero_grad()\n",
    "    preds = waldoFinder(items).squeeze()\n",
    "    \n",
    "    loss = lossFunc(preds, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Batch \", i, \": \", loss.item())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd5e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnv",
   "language": "python",
   "name": "virenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
