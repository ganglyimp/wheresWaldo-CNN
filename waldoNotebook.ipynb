{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Creating new Waldo samples...\n",
      "Converting numpy arrays into tensors...\n"
     ]
    }
   ],
   "source": [
    "# ================\n",
    "#  PREPROCESSING\n",
    "# ================\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as tf \n",
    "from torchvision import datasets\n",
    "#torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "def loadDirectory(filepath, isOrig):\n",
    "    # load directory\n",
    "    files = glob.glob(filepath)\n",
    "\n",
    "    arr = []\n",
    "    for fl in files:\n",
    "        img = cv2.imread(fl)\n",
    "\n",
    "        # resize image to 256x256\n",
    "        if(isOrig != True and img.shape[0] != 256): \n",
    "            img = cv2.resize(img, (256, 256))\n",
    "\n",
    "        arr.append(img)\n",
    "\n",
    "    return arr\n",
    "\n",
    "def numpyToTensor(arr):\n",
    "    #convert to tensor\n",
    "    arr = np.array(arr)\n",
    "    arr = arr.transpose((0, 3, 1, 2))\n",
    "    tensorList = torch.FloatTensor(arr)\n",
    "\n",
    "    return tensorList\n",
    "\n",
    "def createNewWaldoSamples(notWaldos, overlay):\n",
    "    newWaldos = []\n",
    "    oRows, oCols, oChannels = overlay.shape\n",
    "    for img in notWaldos:\n",
    "        newImg = img\n",
    "        iRows, iCols, iChannels = newImg.shape\n",
    "        newImg = np.dstack([newImg, np.ones((iRows, iCols), dtype='uint8') * 255])\n",
    "\n",
    "        randX = random.randint(0, iRows-oRows)\n",
    "        randY = random.randint(0, iCols-oCols)\n",
    "\n",
    "        aOverlay = overlay[:, :, 3] / 255.0\n",
    "        aImg = 1.0 - aOverlay\n",
    "\n",
    "        for c in range(0, 3):\n",
    "            newImg[randX:randX+oRows, randY:randY+oCols, c] = (aOverlay * overlay[:, :, c] + aImg * newImg[randX:randX+oRows, randY:randY+oCols, c])\n",
    "\n",
    "        newWaldos.append(newImg[:, :, :3])\n",
    "    \n",
    "    return newWaldos\n",
    "        \n",
    "# Loading images datasets\n",
    "print(\"Loading dataset...\")\n",
    "originalImg = loadDirectory(\"./original-images/*.jpg\", True)\n",
    "\n",
    "waldo64 = loadDirectory(\"./64/waldo/*.jpg\", False)\n",
    "notWaldo64 = loadDirectory(\"./64/notwaldo/*.jpg\", False)\n",
    "\n",
    "waldo128 = loadDirectory(\"./128/waldo/*.jpg\", False)\n",
    "notWaldo128 = loadDirectory(\"./128/notwaldo/*.jpg\", False)\n",
    "\n",
    "waldo256 = loadDirectory(\"./256/waldo/*.jpg\", False)\n",
    "notWaldo256 = loadDirectory(\"./256/notwaldo/*.jpg\", False)\n",
    "\n",
    "# Creating new Waldo samples by overlaying a Waldo png over a notWaldo sample\n",
    "print(\"Creating new Waldo samples...\")\n",
    "waldoOverlay64 = cv2.imread('./waldo64.png', cv2.IMREAD_UNCHANGED)\n",
    "waldoOverlay128 = cv2.imread('./waldo128.png', cv2.IMREAD_UNCHANGED)\n",
    "waldoOverlay256 = cv2.imread('./waldo256.png', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "moreWaldo64 = createNewWaldoSamples(notWaldo64, waldoOverlay64)\n",
    "moreWaldo128 = createNewWaldoSamples(notWaldo128, waldoOverlay128)\n",
    "moreWaldo256 = createNewWaldoSamples(notWaldo256, waldoOverlay256)\n",
    "\n",
    "# Converting numpy arrays into tensors (TODO: FINISH CONVERSION FUNCTION)\n",
    "print(\"Converting numpy arrays into tensors...\")\n",
    "waldo64Tensor = numpyToTensor(waldo64)\n",
    "waldo128Tensor = numpyToTensor(waldo128)\n",
    "waldo256Tensor = numpyToTensor(waldo256)\n",
    "\n",
    "moreWaldo64Tensor = numpyToTensor(moreWaldo64)\n",
    "moreWaldo128Tensor = numpyToTensor(moreWaldo128)\n",
    "moreWaldo256Tensor = numpyToTensor(moreWaldo256)\n",
    "\n",
    "notWaldo64Tensor = numpyToTensor(notWaldo64)\n",
    "notWaldo128Tensor = numpyToTensor(notWaldo128)\n",
    "notWaldo256Tensor = numpyToTensor(notWaldo256)\n",
    "\n",
    "# Combining into two lists: waldos and not waldos\n",
    "waldos = torch.cat((waldo64Tensor, waldo128Tensor, waldo256Tensor, moreWaldo64Tensor, moreWaldo128Tensor, moreWaldo256Tensor), 0)\n",
    "notWaldos = torch.cat((notWaldo64Tensor, notWaldo128Tensor, notWaldo256Tensor), 0)\n",
    "\n",
    "print(\"Waldo:NotWaldo Count : \", waldos.shape(dim=0), \":\", notWaldos.shape(dim=0))\n",
    "\n",
    "# Create labels & combine\n",
    "waldoLabels = torch.cat((torch.ones(len(waldos)), torch.zeros(len(notWaldos))), 0)\n",
    "allWaldos = torch.cat((waldos, notWaldos), 0)\n",
    "\n",
    "waldoDataset = torch.utils.data.TensorDataset(allWaldos, waldoLabels)\n",
    "print(\"Dataset loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61627227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Initialized\n",
      "Dataset shuffled\n"
     ]
    }
   ],
   "source": [
    "# ============\n",
    "#   THE CNN\n",
    "# ============\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Network should output whether or not the input image has waldo in it\n",
    "class WaldoFinder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WaldoFinder, self).__init__()\n",
    "\n",
    "        # Block 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=256, kernel_size=5, stride=1, padding=2)\n",
    "        self.batchNorm1 = nn.BatchNorm2d(num_features=256)\n",
    "        self.dropout1 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(num_features=128)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.1)\n",
    "\n",
    "        # Block 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=32, stride=1, padding=0)\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    #Forward function - convolvs down to 16x16 image and ultimately outputs 1 or 0\n",
    "    def forward(self, t):\n",
    "        print(\"Initial: \", t.shape)\n",
    "\n",
    "        t = self.conv1(t)\n",
    "        t = self.batchNorm1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout1(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        print(\"Block 1: \", t.shape)\n",
    "\n",
    "        t = self.conv2(t)\n",
    "        t = self.batchNorm2(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout2(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        print(\"Block 2: \", t.shape)\n",
    "\n",
    "        t = self.conv3(t)\n",
    "        t = self.batchNorm3(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.dropout3(t)\n",
    "        t = self.maxPool(t)\n",
    "\n",
    "        print(\"Block 3: \", t.shape)\n",
    "\n",
    "        t = self.conv4(t)\n",
    "\n",
    "        print(\"Final Layer: \", t.shape)\n",
    "\n",
    "        t = torch.round(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "waldoFinder = WaldoFinder()\n",
    "print(\"Network Initialized\")\n",
    "\n",
    "# Divide into training and test set\n",
    "tenPercent = int(len(waldoDataset) * 0.1)\n",
    "ninetyPercent = len(waldoDataset) - tenPercent\n",
    "trainSet, testSet = torch.utils.data.random_split(waldoDataset, [ninetyPercent, tenPercent])\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainSet, shuffle=True, batch_size=10)\n",
    "testLoader = torch.utils.data.DataLoader(testSet, shuffle=True, batch_size=10)\n",
    "print(\"Dataset shuffled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1b3225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining training...\n",
      "Initial:  torch.Size([10, 256, 256, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 3, 5, 5], expected input[10, 256, 256, 3] to have 3 channels, but got 256 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/98/9by9b4t56nj5y36zn3zvh8_m0000gn/T/ipykernel_10821/2436003217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaldoFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/98/9by9b4t56nj5y36zn3zvh8_m0000gn/T/ipykernel_10821/3729104637.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initial: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 442\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 3, 5, 5], expected input[10, 256, 256, 3] to have 3 channels, but got 256 channels instead"
     ]
    }
   ],
   "source": [
    "# Train Loop\n",
    "optimizer = optim.Adam(waldoFinder.parameters(), lr=.01)\n",
    "#lossFunc = nn.CrossEntropyLoss()\n",
    "lossFunc = nn.BCELoss()\n",
    "\n",
    "print(\"Begining training...\")\n",
    "for items, labels in trainLoader:\n",
    "    optimizer.zero_grad()\n",
    "    preds = waldoFinder(items).unsqueeze(dim=0)\n",
    "\n",
    "    loss = lossFunc(preds, labels.unsqueeze(dim=0))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"One loop completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef180a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virEnv",
   "language": "python",
   "name": "virenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
